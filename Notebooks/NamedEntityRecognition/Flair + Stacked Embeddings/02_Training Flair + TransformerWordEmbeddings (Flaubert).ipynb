{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "import flair\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, TransformerWordEmbeddings\n",
    "from typing import List\n",
    "from flair.embeddings import CamembertEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.training_utils import EvaluationMetric\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get the corpus\n",
    "corpus: Corpus  = flair.datasets.WIKINER_FRENCH().downsample(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    TransformerWordEmbeddings('flaubert/flaubert_large_cased')\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. initialize sequence tagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. initialize trainer\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-06 16:42:24,300 Reading data from /Users/amalbedoui/.flair/datasets/wikiner_french\n",
      "2020-12-06 16:42:24,300 Train: /Users/amalbedoui/.flair/datasets/wikiner_french/aij-wikiner-fr-wp3.train\n",
      "2020-12-06 16:42:24,301 Dev: None\n",
      "2020-12-06 16:42:24,302 Test: None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8597517a9e9d469d8ce50e380b8893a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1516.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d7242be9584ef79136a4a0641d390a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1561415.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88089c818b744ea7a9ee15373c93a112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=895731.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af99b8ea8cd4a3f92e9e36cf5fbdaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1493194721.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-12-06 16:44:23,525 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 16:44:23,527 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): TransformerWordEmbeddings(\n",
      "      (model): FlaubertModel(\n",
      "        (position_embeddings): Embedding(512, 1024)\n",
      "        (embeddings): Embedding(68729, 1024, padding_idx=2)\n",
      "        (layer_norm_emb): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attentions): ModuleList(\n",
      "          (0): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (1): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (2): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (3): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (4): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (5): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (6): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (7): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (8): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (9): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (10): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (11): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (12): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (13): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (14): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (15): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (16): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (17): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (18): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (19): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (20): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (21): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (22): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (23): MultiHeadAttention(\n",
      "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (layer_norm1): ModuleList(\n",
      "          (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (4): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (5): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (6): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (7): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (8): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (9): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (10): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (11): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (12): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (13): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (14): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (15): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (16): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (17): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (18): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (19): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (20): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (21): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (22): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (23): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "        (ffns): ModuleList(\n",
      "          (0): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (1): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (2): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (3): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (4): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (5): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (6): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (7): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (8): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (9): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (10): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (11): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (12): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (13): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (14): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (15): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (16): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (17): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (18): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (19): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (20): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (21): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (22): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (23): TransformerFFN(\n",
      "            (lin1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (layer_norm2): ModuleList(\n",
      "          (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (4): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (5): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (6): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (7): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (8): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (9): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (10): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (11): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (12): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (13): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (14): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (15): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (16): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (17): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (18): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (19): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (20): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (21): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (22): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (23): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (rnn): LSTM(4096, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-06 16:44:23,528 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 16:44:23,528 Corpus: \"Corpus: 10713 train + 1190 dev + 1323 test sentences\"\n",
      "2020-12-06 16:44:23,529 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 16:44:23,530 Parameters:\n",
      "2020-12-06 16:44:23,530  - learning_rate: \"0.1\"\n",
      "2020-12-06 16:44:23,531  - mini_batch_size: \"32\"\n",
      "2020-12-06 16:44:23,531  - patience: \"3\"\n",
      "2020-12-06 16:44:23,532  - anneal_factor: \"0.5\"\n",
      "2020-12-06 16:44:23,532  - max_epochs: \"3\"\n",
      "2020-12-06 16:44:23,533  - shuffle: \"True\"\n",
      "2020-12-06 16:44:23,533  - train_with_dev: \"False\"\n",
      "2020-12-06 16:44:23,534  - batch_growth_annealing: \"False\"\n",
      "2020-12-06 16:44:23,534 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 16:44:23,535 Model training base path: \"resources/taggers/example-ner-flaubert\"\n",
      "2020-12-06 16:44:23,535 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 16:44:23,536 Device: cpu\n",
      "2020-12-06 16:44:23,537 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 16:44:23,537 Embeddings storage mode: cpu\n",
      "2020-12-06 16:44:23,542 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 16:52:38,624 epoch 1 - iter 33/335 - loss 22.65484515 - samples/sec: 2.14 - lr: 0.100000\n",
      "2020-12-06 17:01:37,141 epoch 1 - iter 66/335 - loss 18.82751734 - samples/sec: 1.96 - lr: 0.100000\n",
      "2020-12-06 17:10:49,446 epoch 1 - iter 99/335 - loss 16.89493170 - samples/sec: 1.91 - lr: 0.100000\n",
      "2020-12-06 17:19:22,987 epoch 1 - iter 132/335 - loss 15.52934322 - samples/sec: 2.06 - lr: 0.100000\n",
      "2020-12-06 17:28:09,232 epoch 1 - iter 165/335 - loss 14.34569249 - samples/sec: 2.01 - lr: 0.100000\n",
      "2020-12-06 17:36:53,144 epoch 1 - iter 198/335 - loss 13.41804429 - samples/sec: 2.02 - lr: 0.100000\n",
      "2020-12-06 17:45:26,425 epoch 1 - iter 231/335 - loss 12.66772025 - samples/sec: 2.06 - lr: 0.100000\n",
      "2020-12-06 17:54:18,096 epoch 1 - iter 264/335 - loss 12.04453923 - samples/sec: 1.99 - lr: 0.100000\n",
      "2020-12-06 18:03:19,960 epoch 1 - iter 297/335 - loss 11.54614469 - samples/sec: 1.95 - lr: 0.100000\n",
      "2020-12-06 18:13:03,170 epoch 1 - iter 330/335 - loss 11.09411119 - samples/sec: 1.81 - lr: 0.100000\n",
      "2020-12-06 18:14:29,324 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 18:14:29,325 EPOCH 1 done: loss 11.0523 - lr 0.1000000\n",
      "2020-12-06 18:23:22,989 DEV : loss 5.495382785797119 - score 0.6436\n",
      "2020-12-06 18:23:24,135 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-12-06 18:23:27,618 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 18:32:54,181 epoch 2 - iter 33/335 - loss 6.75285256 - samples/sec: 1.87 - lr: 0.100000\n",
      "2020-12-06 18:42:09,562 epoch 2 - iter 66/335 - loss 6.57314864 - samples/sec: 1.90 - lr: 0.100000\n",
      "2020-12-06 18:51:10,052 epoch 2 - iter 99/335 - loss 6.26423042 - samples/sec: 1.96 - lr: 0.100000\n",
      "2020-12-06 19:02:13,208 epoch 2 - iter 132/335 - loss 6.16459111 - samples/sec: 1.59 - lr: 0.100000\n",
      "2020-12-06 19:12:43,975 epoch 2 - iter 165/335 - loss 6.05935198 - samples/sec: 1.68 - lr: 0.100000\n",
      "2020-12-06 19:23:25,270 epoch 2 - iter 198/335 - loss 5.98426216 - samples/sec: 1.65 - lr: 0.100000\n",
      "2020-12-06 19:31:53,415 epoch 2 - iter 231/335 - loss 5.90302583 - samples/sec: 2.08 - lr: 0.100000\n",
      "2020-12-06 19:40:57,354 epoch 2 - iter 264/335 - loss 5.84581631 - samples/sec: 1.94 - lr: 0.100000\n",
      "2020-12-06 19:50:14,929 epoch 2 - iter 297/335 - loss 5.76757275 - samples/sec: 1.90 - lr: 0.100000\n",
      "2020-12-06 19:59:24,459 epoch 2 - iter 330/335 - loss 5.72627704 - samples/sec: 1.92 - lr: 0.100000\n",
      "2020-12-06 20:00:42,328 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 20:00:42,330 EPOCH 2 done: loss 5.7113 - lr 0.1000000\n",
      "2020-12-06 20:08:29,981 DEV : loss 3.8199679851531982 - score 0.704\n",
      "2020-12-06 20:08:31,267 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-12-06 20:08:34,510 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 20:17:46,965 epoch 3 - iter 33/335 - loss 4.82358957 - samples/sec: 1.91 - lr: 0.100000\n",
      "2020-12-06 20:27:09,260 epoch 3 - iter 66/335 - loss 4.70662032 - samples/sec: 1.88 - lr: 0.100000\n",
      "2020-12-06 20:36:24,473 epoch 3 - iter 99/335 - loss 4.72088075 - samples/sec: 1.90 - lr: 0.100000\n",
      "2020-12-06 20:45:48,073 epoch 3 - iter 132/335 - loss 4.68344015 - samples/sec: 1.88 - lr: 0.100000\n",
      "2020-12-06 20:55:02,113 epoch 3 - iter 165/335 - loss 4.59634846 - samples/sec: 1.91 - lr: 0.100000\n",
      "2020-12-06 21:03:55,284 epoch 3 - iter 198/335 - loss 4.60406100 - samples/sec: 1.98 - lr: 0.100000\n",
      "2020-12-06 21:13:47,765 epoch 3 - iter 231/335 - loss 4.51629974 - samples/sec: 1.78 - lr: 0.100000\n",
      "2020-12-06 21:23:04,785 epoch 3 - iter 264/335 - loss 4.44445144 - samples/sec: 1.90 - lr: 0.100000\n",
      "2020-12-06 21:32:29,450 epoch 3 - iter 297/335 - loss 4.41749753 - samples/sec: 1.87 - lr: 0.100000\n",
      "2020-12-06 21:43:03,224 epoch 3 - iter 330/335 - loss 4.33078770 - samples/sec: 1.67 - lr: 0.100000\n",
      "2020-12-06 21:44:32,782 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 21:44:32,783 EPOCH 3 done: loss 4.3274 - lr 0.1000000\n",
      "2020-12-06 21:52:27,966 DEV : loss 2.8995649814605713 - score 0.7685\n",
      "2020-12-06 21:52:29,261 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-12-06 21:52:34,376 ----------------------------------------------------------------------------------------------------\n",
      "2020-12-06 21:52:34,379 Testing using best model ...\n",
      "2020-12-06 21:52:34,383 loading file resources/taggers/example-ner-flaubert/best-model.pt\n",
      "2020-12-06 22:02:30,528 0.7816\t0.7891\t0.7853\n",
      "2020-12-06 22:02:30,532 \n",
      "Results:\n",
      "- F1-score (micro) 0.7853\n",
      "- F1-score (macro) 0.7336\n",
      "\n",
      "By class:\n",
      "LOC        tp: 984 - fp: 246 - fn: 251 - precision: 0.8000 - recall: 0.7968 - f1-score: 0.7984\n",
      "MISC       tp: 269 - fp: 214 - fn: 135 - precision: 0.5569 - recall: 0.6658 - f1-score: 0.6065\n",
      "ORG        tp: 119 - fp: 43 - fn: 110 - precision: 0.7346 - recall: 0.5197 - f1-score: 0.6087\n",
      "PER        tp: 664 - fp: 66 - fn: 48 - precision: 0.9096 - recall: 0.9326 - f1-score: 0.9209\n",
      "2020-12-06 22:02:30,533 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.7853423336547734,\n",
       " 'dev_score_history': [0.6436340371081255,\n",
       "  0.7040235938487466,\n",
       "  0.7684707903780068],\n",
       " 'train_loss_history': [11.052329261267364,\n",
       "  5.711321242887582,\n",
       "  4.327354967772071],\n",
       " 'dev_loss_history': [5.495382785797119,\n",
       "  3.8199679851531982,\n",
       "  2.8995649814605713]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-ner-flaubert',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=3,\n",
    "              checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequenceTagger.load('resources/taggers/example-ner-flaubert/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create example sentence\n",
    "sentence = Sentence('Emma Louise, habite au 26 rue Alexandre, 75005 Paris, France, née le 11/11/1993. Elle travaille chez Zenika et elle est joignable sur 06660006.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 705 ms, sys: 2.02 s, total: 2.72 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict tags and print\n",
    "model.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma <B-PER> Louise <E-PER> , habite au 26 rue Alexandre <S-PER> , 75005 <B-LOC> Paris <E-LOC> , France <S-LOC> , née le 11 / 11 / 1993 . Elle travaille chez Zenika <S-MISC> et elle est joignable sur 06660006 .\n"
     ]
    }
   ],
   "source": [
    "print(sentence.to_tagged_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
