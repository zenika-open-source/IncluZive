{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, classification_report, multilabel_confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "files_true = os.listdir(path+'/data_true')\n",
    "files_pred = os.listdir(path+'/data_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = pd.DataFrame()\n",
    "for f in files_true:\n",
    "    if f.endswith('.xlsx'):\n",
    "        data = pd.read_excel('data_true/'+f,engine='openpyxl')\n",
    "        df_true = df_true.append(data)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame()\n",
    "for f in files_pred:\n",
    "    if f.endswith('.xlsx')  and (f in files_true):\n",
    "        data = pd.read_excel('data_pred/'+f,engine='openpyxl')\n",
    "        df_pred = df_pred.append(data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données annotées manuellement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre total d'entités annotées manuellement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occurrence des entités (true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "df_true['Label'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\n",
    "plt.xlabel(\"Label\", labelpad=14)\n",
    "plt.ylabel(\"Count of entities\", labelpad=14)\n",
    "plt.title(\"Count of entities by label\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true['Entity'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occurences des entités les plus fréquentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.groupby(['Entity','Label']).size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occurences des entités les plus fréquentes au sein de chaque label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_true['Label'].unique():\n",
    "    print('-------',item,'-------')\n",
    "    display(df_true.loc[df_true['Label']==item].groupby(['Entity','Label']).size().sort_values(ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données prédites par l'outil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre total d'entités prédites par l'outil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occurrence des entités (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "df_pred['Label'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\n",
    "plt.xlabel(\"Label\", labelpad=14)\n",
    "plt.ylabel(\"Count of entities\", labelpad=14)\n",
    "plt.title(\"Count of entities by label\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['Entity'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occurences des entités les plus fréquentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.groupby(['Entity','Label']).size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occurences des entités les plus fréquentes au sein de chaque label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_pred['Label'].unique():\n",
    "    print('-------',item,'-------')\n",
    "    display(df_pred.loc[df_pred['Label']==item].groupby(['Entity','Label']).size().sort_values(ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données de l'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=df_pred.drop(['Text'],axis =1,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true=df_true.drop(['Text'],axis =1,errors='ignore')\n",
    "df_true = df_true[df_true['Entity'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_true, df_pred, on=['Entity'], how='outer').drop_duplicates().fillna(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Entity','y_true', 'y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration des données réelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_true'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "df['y_true'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\n",
    "plt.xlabel(\"Label\", labelpad=14)\n",
    "plt.ylabel(\"Count of entities\", labelpad=14)\n",
    "plt.title(\"Count of entities by label (true)\", y=1.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les entités détectées par l'outil par erreur (Faux positifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['y_true']=='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre total de Faux Positifs : \",len(df.loc[df['y_true']=='O']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration des données prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "df['y_pred'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\n",
    "plt.xlabel(\"Label\", labelpad=14)\n",
    "plt.ylabel(\"Count of entities\", labelpad=14)\n",
    "plt.title(\"Count of entities by label (pred)\", y=1.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les entités annotées manuellement mais non détectées par l'outil (Faux négatifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['y_pred']=='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre total de Faux Négatifs : \",len(df.loc[df['y_pred']=='O']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erreurs détectées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_list = ['TEL','PERIODE','EMAIL','LANG', 'URL', 'DATE']\n",
    "regex_error_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['PER','LOC']\n",
    "model_error_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_error_regex = {}\n",
    "dict_error_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = df.loc[(df['y_true']!=df['y_pred'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre d'erreurs détectées : \",len(df_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erreurs détectées par label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df['y_true'].unique():\n",
    "    if(((len(df_error.loc[df_error['y_true']==item])>0)|(len(df_error.loc[df_error['y_pred']==item])>0)) & (item!='O') ):      \n",
    "        print('\\n')\n",
    "        print('-------',item,'-------')\n",
    "        display(df_error.loc[(df_error['y_true']==item)|(df_error['y_pred']==item)])\n",
    "        print('\\n')\n",
    "        if(item in regex_list):\n",
    "            regex_error_count = regex_error_count+len(df_error.loc[(df_error['y_true']==item)|(df_error['y_pred']==item)])\n",
    "            dict_error_regex[item] = len(df_error.loc[(df_error['y_true']==item)|(df_error['y_pred']==item)])\n",
    "        else:\n",
    "            model_error_count = model_error_count+len(df_error.loc[(df_error['y_true']==item)|(df_error['y_pred']==item)])\n",
    "            dict_error_model[item] = len(df_error.loc[(df_error['y_true']==item)|(df_error['y_pred']==item)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources des erreurs détectées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcdefaults()\n",
    "\n",
    "objects = ('Erreurs issues des regex', 'Erreurs issues du modèle')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [regex_error_count,model_error_count]\n",
    "\n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Nombre d\\'erreurs')\n",
    "plt.title('Nombre d\\'erreurs détectées')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Erreurs issues des regex', 'Erreurs issues du modèle'\n",
    "sizes = [regex_error_count, model_error_count]\n",
    "colors = ['lightcoral', 'lightskyblue']\n",
    "explode = (0.1, 0)  # explode 1st slice\n",
    "\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.title('Pourcentage des erreurs détectées')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erreurs détectées par label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_regex_colors = ['lightcoral'] * len(dict_error_regex.values())\n",
    "nbr_model_colors = ['lightskyblue'] * len(dict_error_model.values())\n",
    "labels = list(dict_error_regex.keys())+list(dict_error_model.keys())\n",
    "sizes = list(dict_error_regex.values())+list(dict_error_model.values())\n",
    "colors = nbr_regex_colors+nbr_model_colors\n",
    "explode = [0.1]* len(nbr_regex_colors+nbr_model_colors) \n",
    "plt.pie(sizes, labels=labels, colors=colors, explode=explode ,\n",
    "autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.title('Pourcentage des erreurs détectées par label')\n",
    "plt.axis('equal')\n",
    "plt.legend([\n",
    "        Patch(facecolor='lightcoral'),\n",
    "        Patch(facecolor='lightskyblue')\n",
    "    ], [\"Erreurs issues des regex\", \"Erreurs issues du modèle\"], bbox_to_anchor=[1.5, 1], \n",
    "           loc='upper right', ncol=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_regex_errors = ['regex'] * len(dict_error_regex.values())\n",
    "nbr_model_errors = ['model'] * len(dict_error_model.values())\n",
    "plotdata = pd.DataFrame({\n",
    "    \"pies\": list(dict_error_regex.values())+list(dict_error_model.values()), \n",
    "    \"type\": nbr_regex_errors+nbr_model_errors\n",
    "    }, \n",
    "    index=list(dict_error_regex.keys())+list(dict_error_model.keys())\n",
    ")\n",
    "\n",
    "colours = {\"regex\": \"lightcoral\", \"model\": \"lightskyblue\"}\n",
    "plotdata['pies'].plot(\n",
    "        kind=\"bar\", color=plotdata['type'].replace(colours)\n",
    ").legend(\n",
    "    [\n",
    "        Patch(facecolor=colours['regex']),\n",
    "        Patch(facecolor=colours['model'])\n",
    "    ], [\"Erreurs issues des regex\", \"Erreurs issues du modèle\"], bbox_to_anchor=[1.5, 1], \n",
    "           loc='upper right', ncol=1\n",
    ")\n",
    "plt.title(\"Nombre d'erreurs détectées par label\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Nombre d'erreurs\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}